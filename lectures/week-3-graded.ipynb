{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff832f1c-e6fe-49c2-bda7-d3351cf9c11a",
   "metadata": {},
   "source": [
    "1. Download the Yelp review dataset “Yelp/yelp_review_full”. Split each sample by calling the string method “.split()” and choose the correct statements about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2695bdb6-366c-48c7-af6a-43eee7057084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text'],\n",
       "    num_rows: 700000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('yelp/yelp_review_full', split='all')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ad87aa-67d2-42be-91b3-667c86fd08ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb7a0ec23e7467e8787922c525866a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=12):   0%|          | 0/700000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(lambda x: {'n_tokens': len(x['text'].split())}, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98fe89a-c409-49a4-93bd-37d2d63a709c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.878307\n"
     ]
    }
   ],
   "source": [
    "# The dataset contains close to 99M words?\n",
    "n_words = sum(ds['n_tokens'])\n",
    "print(n_words / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0dac63-3645-4ed3-9238-f3a45a55384e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93878307"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens = 0\n",
    "for sample in ds:\n",
    "    n_tokens += len(sample['text'].split())\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199018ed-0b0f-4f00-b354-d360a40ac289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7543c181f8124cbd9d0996c9fe6ffbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=6):   0%|          | 0/700000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'n_tokens'],\n",
       "    num_rows: 355\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B. There are more than 300 samples that contain a single word\n",
    "ds.filter(lambda x: x['n_tokens'] == 1, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfcaf1c0-cd22-4892-94ce-93818964b0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D. “Cheesy-melty-roasted-cauliflower-with-fresh-bread-crumbs-on top.\\\\nTo-die-for.” is one of the single words in the dataset\n",
    "single_words = ds.filter(lambda x: x['n_tokens'] == 1, num_proc=6)['text']\n",
    "sample = \"Cheesy-melty-roasted-cauliflower-with-fresh-bread-crumbs-on-top.\\\\nTo-die-for.\"\n",
    "sample in single_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5d7d55-3fd3-4c8a-8fcc-70baf7d068e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.11186714285714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E. Average length of a sample is 134.1\n",
    "sum(ds['n_tokens']) / len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6faaa0d8-7a04-43e4-96fe-98ef5cd6b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F. The distribution of the length of the samples is right skewed\n",
    "import pandas as pd\n",
    "s = pd.Series(ds['n_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6397e672-659b-4c84-94c7-ff72dbc72c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqXElEQVR4nO3de1RV553/8Q/XA6gHvAwQKyozZqLUO1Q9SZoxCUIMKxMbm2VSx1JjzNKBjMr8NNJa4qWOjpl4SSShbaJmVmI1zmpsI1ZlsGod8YaSeKk2s2qGrJoDaRXxCkfYvz+62PEIouA5wnl4v9ZyrZxnf8/ez/7i5ZNn731OkGVZlgAAAAwT3NYTAAAA8AdCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASKFtPYG2VF9fr7Nnz6pLly4KCgpq6+kAAIA7YFmWLl68qJ49eyo4+NbrNR065Jw9e1YJCQltPQ0AANAKX3zxhXr16nXL7R065HTp0kXSX5vkdDp9tl+Px6MdO3YoLS1NYWFhPttvR0dffY+e+gd99Q/66h+B2Nfq6molJCTY/47fSocOOQ2XqJxOp89DTlRUlJxOZ8D8hgkE9NX36Kl/0Ff/oK/+Ech9vd2tJtx4DAAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGCk0LaeALz1nVvo9frzpRltNBMAAAIbKzkAAMBIrOQEIFZ7AAC4PVZyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGCm0rSeA5vWdW9jWUwAAICCxkgMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR7irkLF26VEFBQZo5c6Y9du3aNWVlZal79+7q3Lmzxo8fr4qKCq/3lZeXKyMjQ1FRUYqNjdXs2bN1/fp1r5pdu3Zp+PDhcjgc6tevn9atW9fo+Pn5+erbt68iIiI0cuRIHTx48G5OBwAAGKTVIefQoUP66U9/qsGDB3uNz5o1Sx9//LE2bdqk3bt36+zZs3rmmWfs7XV1dcrIyFBtba327dun9957T+vWrVNeXp5dc+bMGWVkZOjRRx9VWVmZZs6cqRdffFHbt2+3azZu3KicnBy9+uqrOnLkiIYMGaL09HRVVla29pQAAIBBWhVyLl26pIkTJ+rnP/+5unbtao9fuHBB7777rpYvX67HHntMycnJWrt2rfbt26f9+/dLknbs2KGTJ0/q/fff19ChQzV27FgtWrRI+fn5qq2tlSQVFBQoMTFRr7/+ugYMGKDs7Gx997vf1YoVK+xjLV++XFOnTtXkyZOVlJSkgoICRUVFac2aNXfTD2P0nVvo9QsAgI4mtDVvysrKUkZGhlJTU/WTn/zEHi8tLZXH41Fqaqo91r9/f/Xu3VslJSUaNWqUSkpKNGjQIMXFxdk16enpmj59uk6cOKFhw4appKTEax8NNQ2XxWpra1VaWqrc3Fx7e3BwsFJTU1VSUnLLedfU1KimpsZ+XV1dLUnyeDzyeDytaUWTGvbVmn06QqxWH6+5/fjy/NrK3fQVTaOn/kFf/YO++kcg9vVO59rikLNhwwYdOXJEhw4darTN7XYrPDxcMTExXuNxcXFyu912zY0Bp2F7w7bmaqqrq3X16lWdP39edXV1TdacOnXqlnNfsmSJFixY0Gh8x44dioqKuuX7WquoqKjF71k2ouXH2bp1623301RNoGpNX9E8euof9NU/6Kt/BFJfr1y5ckd1LQo5X3zxhWbMmKGioiJFRES0amJtKTc3Vzk5Ofbr6upqJSQkKC0tTU6n02fH8Xg8Kioq0pgxYxQWFnbLuoHzt99yW0scn59+2303VRNo7rSvuHP01D/oq3/QV/8IxL42XIm5nRaFnNLSUlVWVmr48OH2WF1dnfbs2aPVq1dr+/btqq2tVVVVlddqTkVFheLj4yVJ8fHxjZ6Canj66saam5/IqqiokNPpVGRkpEJCQhQSEtJkTcM+muJwOORwOBqNh4WF+eUHe7v91tQF+ew4t9t3oPzGvRP++nl1ZPTUP+irf9BX/wikvt7pPFt04/Hjjz+uY8eOqayszP6VkpKiiRMn2v8dFham4uJi+z2nT59WeXm5XC6XJMnlcunYsWNeT0EVFRXJ6XQqKSnJrrlxHw01DfsIDw9XcnKyV019fb2Ki4vtGgAA0LG1aCWnS5cuGjhwoNdYp06d1L17d3t8ypQpysnJUbdu3eR0OvXyyy/L5XJp1KhRkqS0tDQlJSVp0qRJWrZsmdxut+bNm6esrCx7lWXatGlavXq15syZoxdeeEE7d+7Uhx9+qMLCr58SysnJUWZmplJSUjRixAitXLlSly9f1uTJk++qIQAAwAyterqqOStWrFBwcLDGjx+vmpoapaen66233rK3h4SEaMuWLZo+fbpcLpc6deqkzMxMLVy40K5JTExUYWGhZs2apVWrVqlXr1565513lJ7+9X0lEyZM0FdffaW8vDy53W4NHTpU27Zta3QzMgAA6JjuOuTs2rXL63VERITy8/OVn59/y/f06dPntk/7jB49WkePHm22Jjs7W9nZ2Xc8V1PxOTgAADTGd1cBAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKTQtp4A2k7fuYVerz9fmtFGMwEAwPcIOffQzaECAAD4D5erAACAkQg5AADASIQcAABgJO7J6SC4HwgA0NGwkgMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADBSi0LO22+/rcGDB8vpdMrpdMrlcuk3v/mNvf3atWvKyspS9+7d1blzZ40fP14VFRVe+ygvL1dGRoaioqIUGxur2bNn6/r16141u3bt0vDhw+VwONSvXz+tW7eu0Vzy8/PVt29fRUREaOTIkTp48GBLTgUAABiuRSGnV69eWrp0qUpLS3X48GE99thjevrpp3XixAlJ0qxZs/Txxx9r06ZN2r17t86ePatnnnnGfn9dXZ0yMjJUW1urffv26b333tO6deuUl5dn15w5c0YZGRl69NFHVVZWppkzZ+rFF1/U9u3b7ZqNGzcqJydHr776qo4cOaIhQ4YoPT1dlZWVd9sPAABgiBaFnKeeekpPPvmk7r//fv393/+9Fi9erM6dO2v//v26cOGC3n33XS1fvlyPPfaYkpOTtXbtWu3bt0/79++XJO3YsUMnT57U+++/r6FDh2rs2LFatGiR8vPzVVtbK0kqKChQYmKiXn/9dQ0YMEDZ2dn67ne/qxUrVtjzWL58uaZOnarJkycrKSlJBQUFioqK0po1a3zYGgAAEMhCW/vGuro6bdq0SZcvX5bL5VJpaak8Ho9SU1Ptmv79+6t3794qKSnRqFGjVFJSokGDBikuLs6uSU9P1/Tp03XixAkNGzZMJSUlXvtoqJk5c6Ykqba2VqWlpcrNzbW3BwcHKzU1VSUlJc3OuaamRjU1Nfbr6upqSZLH45HH42ltKxpp2NfN+3SEWD47hj/4sgf+cKu+ovXoqX/QV/+gr/4RiH2907m2OOQcO3ZMLpdL165dU+fOnfXRRx8pKSlJZWVlCg8PV0xMjFd9XFyc3G63JMntdnsFnIbtDduaq6murtbVq1d1/vx51dXVNVlz6tSpZue+ZMkSLViwoNH4jh07FBUVdfuTb6GioiKv18tG+PwQPrV169a2nsIdubmvuHv01D/oq3/QV/8IpL5euXLljupaHHIeeOABlZWV6cKFC/qv//ovZWZmavfu3S2eYFvIzc1VTk6O/bq6uloJCQlKS0uT0+n02XE8Ho+Kioo0ZswYhYWF2eMD529v5l1t7/j89LaeQrNu1Ve0Hj31D/rqH/TVPwKxrw1XYm6nxSEnPDxc/fr1kyQlJyfr0KFDWrVqlSZMmKDa2lpVVVV5reZUVFQoPj5ekhQfH9/oKaiGp69urLn5iayKigo5nU5FRkYqJCREISEhTdY07ONWHA6HHA5Ho/GwsDC//GBv3m9NXZDPj+FLgfKb218/r46MnvoHffUP+uofgdTXO53nXX9OTn19vWpqapScnKywsDAVFxfb206fPq3y8nK5XC5Jksvl0rFjx7yegioqKpLT6VRSUpJdc+M+Gmoa9hEeHq7k5GSvmvr6ehUXF9s1AAAALVrJyc3N1dixY9W7d29dvHhR69ev165du7R9+3ZFR0drypQpysnJUbdu3eR0OvXyyy/L5XJp1KhRkqS0tDQlJSVp0qRJWrZsmdxut+bNm6esrCx7hWXatGlavXq15syZoxdeeEE7d+7Uhx9+qMLCQnseOTk5yszMVEpKikaMGKGVK1fq8uXLmjx5sg9bAwAAAlmLQk5lZaW+//3v68svv1R0dLQGDx6s7du3a8yYMZKkFStWKDg4WOPHj1dNTY3S09P11ltv2e8PCQnRli1bNH36dLlcLnXq1EmZmZlauHChXZOYmKjCwkLNmjVLq1atUq9evfTOO+8oPf3r+0UmTJigr776Snl5eXK73Ro6dKi2bdvW6GZkAADQcbUo5Lz77rvNbo+IiFB+fr7y8/NvWdOnT5/bPsUzevRoHT16tNma7OxsZWdnN1sDAAA6Lr67CgAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkVr9BZ0wT9+5hY3GPl+a0QYzAQDg7hFy0Kybgw+hBwAQKLhcBQAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMFNrWE0Bg6Tu3sNHY50sz2mAmAAA0j5UcAABgJEIOAAAwEpercNduvoTF5SsAQHvASg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGalHIWbJkib71rW+pS5cuio2N1bhx43T69GmvmmvXrikrK0vdu3dX586dNX78eFVUVHjVlJeXKyMjQ1FRUYqNjdXs2bN1/fp1r5pdu3Zp+PDhcjgc6tevn9atW9doPvn5+erbt68iIiI0cuRIHTx4sCWnAwAADNaikLN7925lZWVp//79KioqksfjUVpami5fvmzXzJo1Sx9//LE2bdqk3bt36+zZs3rmmWfs7XV1dcrIyFBtba327dun9957T+vWrVNeXp5dc+bMGWVkZOjRRx9VWVmZZs6cqRdffFHbt2+3azZu3KicnBy9+uqrOnLkiIYMGaL09HRVVlbeTT8AAIAhQltSvG3bNq/X69atU2xsrEpLS/XII4/owoULevfdd7V+/Xo99thjkqS1a9dqwIAB2r9/v0aNGqUdO3bo5MmT+u///m/FxcVp6NChWrRokV555RXNnz9f4eHhKigoUGJiol5//XVJ0oABA7R3716tWLFC6enpkqTly5dr6tSpmjx5siSpoKBAhYWFWrNmjebOnXvXjQEAAIHtru7JuXDhgiSpW7dukqTS0lJ5PB6lpqbaNf3791fv3r1VUlIiSSopKdGgQYMUFxdn16Snp6u6ulonTpywa27cR0NNwz5qa2tVWlrqVRMcHKzU1FS7BgAAdGwtWsm5UX19vWbOnKmHHnpIAwcOlCS53W6Fh4crJibGqzYuLk5ut9uuuTHgNGxv2NZcTXV1ta5evarz58+rrq6uyZpTp07dcs41NTWqqamxX1dXV0uSPB6PPB7PnZ76bTXs6+Z9OkIsnx2jPfNlL5var7/23xHRU/+gr/5BX/0jEPt6p3NtdcjJysrS8ePHtXfv3tbu4p5bsmSJFixY0Gh8x44dioqK8vnxioqKvF4vG+HzQ7RLW7du9ev+b+4r7h499Q/66h/01T8Cqa9Xrly5o7pWhZzs7Gxt2bJFe/bsUa9evezx+Ph41dbWqqqqyms1p6KiQvHx8XbNzU9BNTx9dWPNzU9kVVRUyOl0KjIyUiEhIQoJCWmypmEfTcnNzVVOTo79urq6WgkJCUpLS5PT6WxBB5rn8XhUVFSkMWPGKCwszB4fOH97M+8yx/H56X7Z7636itajp/5BX/2DvvpHIPa14UrM7bQo5FiWpZdfflkfffSRdu3apcTERK/tycnJCgsLU3FxscaPHy9JOn36tMrLy+VyuSRJLpdLixcvVmVlpWJjYyX9NT06nU4lJSXZNTevBhQVFdn7CA8PV3JysoqLizVu3DhJf718VlxcrOzs7FvO3+FwyOFwNBoPCwvzyw/25v3W1AX5/Bjtkb//kPjr59WR0VP/oK/+QV/9I5D6eqfzbFHIycrK0vr16/WrX/1KXbp0se+hiY6OVmRkpKKjozVlyhTl5OSoW7ducjqdevnll+VyuTRq1ChJUlpampKSkjRp0iQtW7ZMbrdb8+bNU1ZWlh1Apk2bptWrV2vOnDl64YUXtHPnTn344YcqLCy055KTk6PMzEylpKRoxIgRWrlypS5fvmw/bQUAADq2FoWct99+W5I0evRor/G1a9fqBz/4gSRpxYoVCg4O1vjx41VTU6P09HS99dZbdm1ISIi2bNmi6dOny+VyqVOnTsrMzNTChQvtmsTERBUWFmrWrFlatWqVevXqpXfeecd+fFySJkyYoK+++kp5eXlyu90aOnSotm3b1uhmZAAA0DG1+HLV7URERCg/P1/5+fm3rOnTp89tb04dPXq0jh492mxNdnZ2s5en0H70nVvo9frzpRltNBMAQEfR6qergFu5OdAAANAW+IJOAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASKFtPQF0TH3nFjYa+3xpRhvMBABgKlZyAACAkVjJQbtx8+oOKzsAgLtByPGjgfO3q6YuqK2nAQBAh8TlKgAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGCk0LaeAHArfecWer12hFhaNqKNJgMACDis5AAAACOxkoOAM3D+dtXUBUmSPl+a0cazAQC0V6zkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIwU2tYTAO5G37mFjcY+X5rRBjMBALQ3LV7J2bNnj5566in17NlTQUFB2rx5s9d2y7KUl5en++67T5GRkUpNTdVnn33mVXPu3DlNnDhRTqdTMTExmjJlii5duuRV8+mnn+rb3/62IiIilJCQoGXLljWay6ZNm9S/f39FRERo0KBB2rp1a0tPBwbqO7fQ6xcAoGNqcci5fPmyhgwZovz8/Ca3L1u2TG+88YYKCgp04MABderUSenp6bp27ZpdM3HiRJ04cUJFRUXasmWL9uzZo5deesneXl1drbS0NPXp00elpaV67bXXNH/+fP3sZz+za/bt26fnn39eU6ZM0dGjRzVu3DiNGzdOx48fb+kpAQAAA7X4ctXYsWM1duzYJrdZlqWVK1dq3rx5evrppyVJ//mf/6m4uDht3rxZzz33nH7/+99r27ZtOnTokFJSUiRJb775pp588kn9x3/8h3r27KkPPvhAtbW1WrNmjcLDw/XNb35TZWVlWr58uR2GVq1apSeeeEKzZ8+WJC1atEhFRUVavXq1CgoKWtUMAABgDp/ek3PmzBm53W6lpqbaY9HR0Ro5cqRKSkr03HPPqaSkRDExMXbAkaTU1FQFBwfrwIED+s53vqOSkhI98sgjCg8Pt2vS09P17//+7zp//ry6du2qkpIS5eTkeB0/PT290eWzG9XU1KimpsZ+XV1dLUnyeDzyeDx3e/q2hn05gi2f7RNf97OlffXlz9Y0Db2hR75FX/2DvvpHIPb1Tufq05DjdrslSXFxcV7jcXFx9ja3263Y2FjvSYSGqlu3bl41iYmJjfbRsK1r165yu93NHqcpS5Ys0YIFCxqN79ixQ1FRUXdyii2yKKXe5/tEy/vKvVq3V1RU1NZTMBJ99Q/66h+B1NcrV67cUV2HeroqNzfXa/WnurpaCQkJSktLk9Pp9NlxPB6PioqK9OPDwaqpD/LZfjs6R7ClRSn1Le7r8fnpfpxVYGv4vTpmzBiFhYW19XSMQV/9g776RyD2teFKzO34NOTEx8dLkioqKnTffffZ4xUVFRo6dKhdU1lZ6fW+69ev69y5c/b74+PjVVFR4VXT8Pp2NQ3bm+JwOORwOBqNh4WF+eUHW1MfpJo6Qo6vtbSvgfKHti35689AR0df/YO++kcg9fVO5+nTDwNMTExUfHy8iouL7bHq6modOHBALpdLkuRyuVRVVaXS0lK7ZufOnaqvr9fIkSPtmj179nhdcysqKtIDDzygrl272jU3HqehpuE4AACgY2txyLl06ZLKyspUVlYm6a83G5eVlam8vFxBQUGaOXOmfvKTn+jXv/61jh07pu9///vq2bOnxo0bJ0kaMGCAnnjiCU2dOlUHDx7U//zP/yg7O1vPPfecevbsKUn63ve+p/DwcE2ZMkUnTpzQxo0btWrVKq9LTTNmzNC2bdv0+uuv69SpU5o/f74OHz6s7Ozsu+8KAAAIeC2+XHX48GE9+uij9uuG4JGZmal169Zpzpw5unz5sl566SVVVVXp4Ycf1rZt2xQREWG/54MPPlB2drYef/xxBQcHa/z48XrjjTfs7dHR0dqxY4eysrKUnJysHj16KC8vz+uzdB588EGtX79e8+bN0w9/+EPdf//92rx5swYOHNiqRgAAALO0OOSMHj1alnXrR3iDgoK0cOFCLVy48JY13bp10/r165s9zuDBg/W73/2u2Zpnn31Wzz77bPMTBgAAHRJf0AkAAIxEyAEAAEYi5AAAACN1qA8DRMfU1DeRf740ow1mAgC4lwg56JBuDj6EHgAwD5erAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkvrsKUNNf4nkzvt8KAAILKzkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACPxOTnAXbj583X4LB0AaD8IOcAdupMPDAQAtB9crgIAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGInPyQF86E4+S4cPDASAe4OVHAAAYCRCDgAAMBIhBwAAGImQAwAAjMSNx0A7wLeZA4DvEXKAe4xvMweAe4PLVQAAwEiEHAAAYCRCDgAAMBIhBwAAGIkbj4F2iK+HAIC7x0oOAAAwEiEHAAAYictVQIBq6pIWl7AA4Gus5AAAACOxkgMYhK+HAICvsZIDAACMxEoOYLDbPYruCLG0bMQ9mgwA3GOs5AAAACMRcgAAgJG4XAVAA+dvV01dkP2aG5YBmICQA6ARPoMHgAkIOQDuCN+nBSDQcE8OAAAwEis5AHyGDyME0J4QcgD4Dff2AGhLhBwA9xT39gC4Vwg5ANodLnsB8AVCDoB2j8teAFqDkAMgIN3JZa+bEYyAjoWQA6DD4H4goGMJ+JCTn5+v1157TW63W0OGDNGbb76pESP4WmUArdOaFaKb8e3uQPsQ0CFn48aNysnJUUFBgUaOHKmVK1cqPT1dp0+fVmxsbFtPD0AHd/N3gt2sqVUjbroGfCegQ87y5cs1depUTZ48WZJUUFCgwsJCrVmzRnPnzm3j2QFA8+5k1cgXK0t3ikAF0wRsyKmtrVVpaalyc3PtseDgYKWmpqqkpKTJ99TU1KimpsZ+feHCBUnSuXPn5PF4fDY3j8ejK1euKNQTrLr6W/9fHFomtN7SlSv19NWH6Kl/BGpf+/2/D9t6Cs1yBFuaN6xeQ3/0S9UEUF9b40Du4/fsWA3/Zv3lL39RWFjYPTvu3bh48aIkybKsZusCNuT8+c9/Vl1dneLi4rzG4+LidOrUqSbfs2TJEi1YsKDReGJiol/mCN/7XltPwED01D/oq390lL72eL2tZxAYLl68qOjo6FtuD9iQ0xq5ubnKycmxX9fX1+vcuXPq3r27goJ8938F1dXVSkhI0BdffCGn0+mz/XZ09NX36Kl/0Ff/oK/+EYh9tSxLFy9eVM+ePZutC9iQ06NHD4WEhKiiosJrvKKiQvHx8U2+x+FwyOFweI3FxMT4a4pyOp0B8xsmkNBX36On/kFf/YO++keg9bW5FZwGwfdgHn4RHh6u5ORkFRcX22P19fUqLi6Wy+Vqw5kBAID2IGBXciQpJydHmZmZSklJ0YgRI7Ry5UpdvnzZftoKAAB0XAEdciZMmKCvvvpKeXl5crvdGjp0qLZt29boZuR7zeFw6NVXX210aQx3h776Hj31D/rqH/TVP0zua5B1u+evAAAAAlDA3pMDAADQHEIOAAAwEiEHAAAYiZADAACMRMjxsfz8fPXt21cREREaOXKkDh482NZTareWLFmib33rW+rSpYtiY2M1btw4nT592qvm2rVrysrKUvfu3dW5c2eNHz++0QdAlpeXKyMjQ1FRUYqNjdXs2bN1/fr1e3kq7drSpUsVFBSkmTNn2mP0tXX+9Kc/6Z/+6Z/UvXt3RUZGatCgQTp8+LC93bIs5eXl6b777lNkZKRSU1P12Wefee3j3LlzmjhxopxOp2JiYjRlyhRdunTpXp9Ku1FXV6cf//jHSkxMVGRkpP7u7/5OixYt8vpOIvp6e3v27NFTTz2lnj17KigoSJs3b/ba7qsefvrpp/r2t7+tiIgIJSQkaNmyZf4+tbtjwWc2bNhghYeHW2vWrLFOnDhhTZ061YqJibEqKiraemrtUnp6urV27Vrr+PHjVllZmfXkk09avXv3ti5dumTXTJs2zUpISLCKi4utw4cPW6NGjbIefPBBe/v169etgQMHWqmpqdbRo0etrVu3Wj169LByc3Pb4pTanYMHD1p9+/a1Bg8ebM2YMcMep68td+7cOatPnz7WD37wA+vAgQPWH//4R2v79u3W//7v/9o1S5cutaKjo63Nmzdbn3zyifWP//iPVmJionX16lW75oknnrCGDBli7d+/3/rd735n9evXz3r++efb4pTahcWLF1vdu3e3tmzZYp05c8batGmT1blzZ2vVqlV2DX29va1bt1o/+tGPrF/+8peWJOujjz7y2u6LHl64cMGKi4uzJk6caB0/ftz6xS9+YUVGRlo//elP79Vpthghx4dGjBhhZWVl2a/r6uqsnj17WkuWLGnDWQWOyspKS5K1e/duy7Isq6qqygoLC7M2bdpk1/z+97+3JFklJSWWZf31D3ZwcLDldrvtmrfffttyOp1WTU3NvT2BdubixYvW/fffbxUVFVn/8A//YIcc+to6r7zyivXwww/fcnt9fb0VHx9vvfbaa/ZYVVWV5XA4rF/84heWZVnWyZMnLUnWoUOH7Jrf/OY3VlBQkPWnP/3Jf5NvxzIyMqwXXnjBa+yZZ56xJk6caFkWfW2Nm0OOr3r41ltvWV27dvX6O+CVV16xHnjgAT+fUetxucpHamtrVVpaqtTUVHssODhYqampKikpacOZBY4LFy5Ikrp16yZJKi0tlcfj8epp//791bt3b7unJSUlGjRokNcHQKanp6u6ulonTpy4h7Nvf7KyspSRkeHVP4m+ttavf/1rpaSk6Nlnn1VsbKyGDRumn//85/b2M2fOyO12e/U1OjpaI0eO9OprTEyMUlJS7JrU1FQFBwfrwIED9+5k2pEHH3xQxcXF+sMf/iBJ+uSTT7R3716NHTtWEn31BV/1sKSkRI888ojCw8PtmvT0dJ0+fVrnz5+/R2fTMgH9icftyZ///GfV1dU1+rTluLg4nTp1qo1mFTjq6+s1c+ZMPfTQQxo4cKAkye12Kzw8vNGXqMbFxcntdts1TfW8YVtHtWHDBh05ckSHDh1qtI2+ts4f//hHvf3228rJydEPf/hDHTp0SP/yL/+i8PBwZWZm2n1pqm839jU2NtZre2hoqLp169Zh+zp37lxVV1erf//+CgkJUV1dnRYvXqyJEydKEn31AV/10O12KzExsdE+GrZ17drVL/O/G4QctAtZWVk6fvy49u7d29ZTCXhffPGFZsyYoaKiIkVERLT1dIxRX1+vlJQU/du//ZskadiwYTp+/LgKCgqUmZnZxrMLXB9++KE++OADrV+/Xt/85jdVVlammTNnqmfPnvQVd43LVT7So0cPhYSENHpCpaKiQvHx8W00q8CQnZ2tLVu26Le//a169eplj8fHx6u2tlZVVVVe9Tf2ND4+vsmeN2zriEpLS1VZWanhw4crNDRUoaGh2r17t9544w2FhoYqLi6OvrbCfffdp6SkJK+xAQMGqLy8XNLXfWnu74D4+HhVVlZ6bb9+/brOnTvXYfs6e/ZszZ07V88995wGDRqkSZMmadasWVqyZIkk+uoLvuphIP69QMjxkfDwcCUnJ6u4uNgeq6+vV3FxsVwuVxvOrP2yLEvZ2dn66KOPtHPnzkbLoMnJyQoLC/Pq6enTp1VeXm731OVy6dixY15/OIuKiuR0Ohv9g9RRPP744zp27JjKysrsXykpKZo4caL93/S15R566KFGH3Hwhz/8QX369JEkJSYmKj4+3quv1dXVOnDggFdfq6qqVFpaatfs3LlT9fX1Gjly5D04i/bnypUrCg72/qcoJCRE9fX1kuirL/iqhy6XS3v27JHH47FrioqK9MADD7TLS1WSeITclzZs2GA5HA5r3bp11smTJ62XXnrJiomJ8XpCBV+bPn26FR0dbe3atcv68ssv7V9Xrlyxa6ZNm2b17t3b2rlzp3X48GHL5XJZLpfL3t7wqHNaWppVVlZmbdu2zfqbv/mbDv2oc1NufLrKsuhraxw8eNAKDQ21Fi9ebH322WfWBx98YEVFRVnvv/++XbN06VIrJibG+tWvfmV9+umn1tNPP93kY7rDhg2zDhw4YO3du9e6//77O9SjzjfLzMy0vvGNb9iPkP/yl7+0evToYc2ZM8euoa+3d/HiRevo0aPW0aNHLUnW8uXLraNHj1r/93//Z1mWb3pYVVVlxcXFWZMmTbKOHz9ubdiwwYqKiuIR8o7kzTfftHr37m2Fh4dbI0aMsPbv39/WU2q3JDX5a+3atXbN1atXrX/+53+2unbtakVFRVnf+c53rC+//NJrP59//rk1duxYKzIy0urRo4f1r//6r5bH47nHZ9O+3Rxy6GvrfPzxx9bAgQMth8Nh9e/f3/rZz37mtb2+vt768Y9/bMXFxVkOh8N6/PHHrdOnT3vV/OUvf7Gef/55q3PnzpbT6bQmT55sXbx48V6eRrtSXV1tzZgxw+rdu7cVERFh/e3f/q31ox/9yOsxZfp6e7/97W+b/Ps0MzPTsizf9fCTTz6xHn74YcvhcFjf+MY3rKVLl96rU2yVIMu64WMlAQAADME9OQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAY6f8D0MqUv+Oa6JkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6432b-4967-46aa-a6f7-9ae49d7acb43",
   "metadata": {},
   "source": [
    "2. Load the “bert-base-uncased” pre-trained tokenizer and choose the correct statements about the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da03a81b-a6dd-4877-944b-88ce0c6db6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaidevd/conda/envs/dlp/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34293cba-2774-42bb-abcb-1e1b16c172fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8daee81f-ece4-47d8-8a68-666b08091690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. The tokenizer is used for the BERT model with the context length of 512\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46067892-7879-4e45-8142-825354e20ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B. The tokenizer has 5 special tokens\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e815a83-0340-4c2e-a476-53a45cfa8e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e3db33c-af05-43e3-84bd-f0d2501fcaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4c80631ceb48d0b251f5f2764d8a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/700000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12441"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C. Tokenizing a sample that contains more than 512 words would result in truncation of all tokens beyond the length 512\n",
    "\n",
    "# Pick a sample that's too long from the yelp dataset\n",
    "long = ds.filter(lambda x: x['n_tokens'] > 512)\n",
    "len(long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb1245a4-7634-4bf2-95d9-44c8aebbaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = long['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6d75d2c-90a8-4a41-aeb4-c9ac54ba0e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer(sample)\n",
    "print(len(enc['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f25b8a3-ef2b-44bc-8ff1-bedf0cd4ca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long['n_tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f60ea3-8b83-40d7-895a-d9ecf326095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Tokenizer inserts all the special tokens when it processes a single sample as an input\n",
    "# E. Tokenizer inserts [CLS] and [SEP] special tokens when it processes a single sample as an input\n",
    "# F. Tokenizer inserts only [CLS]special token when it processes a single sample as an input\n",
    "\n",
    "# select a few random samples\n",
    "import random\n",
    "n_samples = 5\n",
    "ix = random.choices(range(len(ds)), k=n_samples)\n",
    "enc = tokenizer(ds.select(ix)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bda30724-4cce-46e3-96ef-cf513911fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] # aroundchandler so i finally made it here. so much hype about this place. now i don't consider myself your average wing eater. i eat a serious amount of buffalo wings. i even made it to state championship for a wing eating contest. the wings here are good. the wings them self are average, but the sauces are way above average. i always judge wings based on the standard hot. the hot was fairly hot, but very tasty. i also tried the atl rub. the flavor was fantastic. i'm not a cool aid drinker, i stay away from sugar. but the fact they had cool aid i thought was pretty cool. i will be a regular here and will try all 18 flavors of wings!! # chandleraz [SEP]\n",
      "[CLS] i tried the satay meal with 2 chicken satays and it was great! the chicken was nicely marinated and came with several sides to make it a meal. the woman taking orders was very friendly and the food was made within 10 mins of ordering. the meal was $ 9, a little much for a small lunch meal but it was pretty filling and tasty! [SEP]\n",
      "[CLS] i have nothing good to say about this place. i've been here on several occasions over the years and here's what i have observed : \\ n \\ n1 - if the place is crowded ( which it almost always is ) expect terrible service from your waiter / bartender. waitstaff has a pretty poor knowledge of their own drink menu. \\ n \\ n2 - the food will be overpriced / sub par. on one occasion me and my entire party got food poisoning from their fried calamari \\ n \\ n3 - you will be seated somewhere awkward / uncomfortable. the interior is cool looking but not functional, gets very congested when there are big crowds. \\ n \\ nthere are plenty of other bar / restaurant destinations in pittsburgh that can deliver and execute the same idea in a much better way. avoid harris grill. [SEP]\n",
      "[CLS] first time trying soul cafe for breakfast. service was very poor as it took 45 minutes for my kids food to come and another 10 for mine. everyone on the patio was waiting similar times. food was mediocre at best. bacon in the blueberry bacon pancakes was undercooked and sparse with a side of cold eggs. the biscuits and gravy were fair. the chicken fried steak was fine. if you are looking for a good breakfast i would recommend jj's nearby or over easy on bell. [SEP]\n",
      "[CLS] we have used this business since the early 90's. i highly recommend them. i also recommend the yearly checkup where they take a look at your a / c. do this in the spring, and get your a / c tuned up for the summer. we have had the same technician, who's name i don't remember, come out here for years. this is a family run business that appears to retain it's employees over the long - run, and that tells me something right there! [SEP]\n"
     ]
    }
   ],
   "source": [
    "for token_ids in enc['input_ids']:\n",
    "    print(tokenizer.decode(token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19d996-5b6d-4a57-9ae8-c4be1bc5897a",
   "metadata": {},
   "source": [
    "3. Use “BertConfig” and “BertForMaskedLM” to construct the default (original) BERT model. Choose the correct statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48761bea-cb44-4c6b-a04f-12076b79b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForMaskedLM\n",
    "cfg = BertConfig()\n",
    "model = BertForMaskedLM(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "398b4df0-e362-4043-a027-a54ea3cd3f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.44.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  A. The model has 12 Bert layers\n",
    "# B. The model has 6 Bert layers\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7be77ad-c1f9-47ea-886a-f1a4d9a56261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.440896\n"
     ]
    }
   ],
   "source": [
    "# C. The model uses absolute position embeddings - yes.\n",
    "# D. The word embedding (token embedding) layer has about 23 million learnable parameters\n",
    "n_params = 0\n",
    "for p in model.bert.embeddings.word_embeddings.parameters():\n",
    "    n_params += p.numel()\n",
    "print(n_params / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5fc491d-479b-4437-8998-5743d7de985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.514298\n"
     ]
    }
   ],
   "source": [
    "# E. The total number of parameters in the model is close to 110 million\n",
    "n_params = 0\n",
    "for p in model.parameters():\n",
    "    n_params += p.numel()\n",
    "print(n_params / 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d2f7b-9a83-489a-a49f-d07fbe3f5f8f",
   "metadata": {},
   "source": [
    "4.  Double the context length from 512 to 1024 (you can change it in the configuration). Count the number of parameters and enter the change in the number of parameters (in millions) compared to the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cccbf2f-efd0-462c-b205-77aaea0b92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.907514\n"
     ]
    }
   ],
   "source": [
    "cfg = BertConfig(max_position_embeddings=1024)\n",
    "model = BertForMaskedLM(cfg)\n",
    "\n",
    "n_params = 0\n",
    "for p in model.parameters():\n",
    "    n_params += p.numel()\n",
    "print(n_params / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "997eb2fa-765b-43f6-b7c4-2c49e4795dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285dcbb-e3e5-41d1-8deb-81881b8081ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "5. Pack (chunk) the samples such that the length of all the samples in the dataset is 512 (for efficient training). Define a mapping function that implements the following procedure\n",
    "\n",
    "  * Take a batch of 1000 samples\n",
    "  * Tokenize it to get input IDs and attention mask\n",
    "  * Concatenate all the input IDs\n",
    "  * Chunk the concatenated IDs into a size of 512\n",
    "  * Drop the last chunk if its length is less than 512\n",
    "  * Pack all the chunks\n",
    "  * Iterate over all the batches in the dataset \n",
    "\n",
    "Store the resulting dataset in the variable “ds_chunked”. Enter the total number of samples in the new dataset.\n",
    "Note: the batch size should be kept at 1000 while calling \"ds.map()\" for theanswer to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0823ef5-bf09-4e5b-b8ba-249b8dcc67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b1c5705-0500-48b8-956f-d521935fc32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109839753d8d4c0bac08feb76b29787b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'n_tokens', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 702\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk(batch):\n",
    "    enc = tokenizer(batch['text'])\n",
    "    input_ids = list(chain(*enc['input_ids']))\n",
    "    attention_mask = list(chain(*enc['attention_mask']))\n",
    "    remainder = len(input_ids) % 512\n",
    "    input_ids = input_ids[:-remainder]\n",
    "    attention_mask = attention_mask[:-remainder]\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "ds_chunked = ds.batch(1000, num_proc=6).map(chunk, num_proc=9)\n",
    "ds_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d54c9a51-55c6-4d9d-a493-1f8f6040c7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed6101540184048b0faa68214f6dc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/700000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try another way\n",
    "\n",
    "def chunk(batch):\n",
    "    enc = tokenizer(batch['text'])\n",
    "    input_ids = enc['input_ids']\n",
    "    attention_masks = enc['attention_mask']\n",
    "    new_input_ids = []\n",
    "    for sample in input_ids:\n",
    "        new_input_ids.extend(sample)\n",
    "    new_attention_mask = []\n",
    "    for sample in attention_masks:\n",
    "        new_attention_mask.extend(sample)\n",
    "    assert len(new_input_ids) == len(new_attention_mask)\n",
    "    remainder = len(new_input_ids) % 512\n",
    "    new_input_ids, new_attention_mask = new_input_ids[:-remainder], new_attention_mask[:-remainder]\n",
    "    return {'input_ids': [new_input_ids], 'attention_mask': [new_attention_mask]}\n",
    "        \n",
    "    \n",
    "xx = ds.map(chunk, batched=True, batch_size=1000, num_proc=9, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ec2f180-83e9-4eac-ba61-8d023cc32717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 702\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c992f375-6654-4b7d-96e2-f6033df85875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221c7ef7a7c64c06b2d69104d399ac0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/700000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 245985\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk(batch):\n",
    "    enc = tokenizer(batch['text'])\n",
    "    input_ids = list(chain(*enc['input_ids']))\n",
    "    attention_mask = list(chain(*enc['attention_mask']))\n",
    "    remainder = len(input_ids) % 512\n",
    "    input_ids = input_ids[:-remainder]\n",
    "    attention_mask = attention_mask[:-remainder]\n",
    "    input_ids = [input_ids[i:(i+512)] for i in range(0, len(input_ids), 512)]\n",
    "    attention_mask = [attention_mask[i:(i+512)] for i in range(0, len(attention_mask), 512)]\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "ds_chunked = ds.map(chunk, num_proc=9, batched=True, batch_size=1000, remove_columns=ds.column_names)\n",
    "ds_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cab8d8f3-6494-44a1-b93e-391f5d3be5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'n_tokens'],\n",
       "    num_rows: 700000\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "140b5290-05bf-4c5e-8db7-1d634de1bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.845701973697583"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)  / len(ds_chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b222c-0b81-41f9-b5fe-0a2991ee655a",
   "metadata": {},
   "source": [
    "6. Split the new dataset into training and test sets with the test_size=0.05 and seed=42. Use the appropriate data collator function for the MLM objective and set the masking probability to 0.2. Use the data loader from PyTorch to load a batch of samples, and enter the token ID corresponding to the unmasked token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bca664f3-b0aa-4d66-95d1-d8582d32b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_split = ds_chunked.train_test_split(test_size=0.05, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ac143b6-a672-4346-a728-f429b0e38cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 233685\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 12300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "59cf129e-6b0d-4145-8427-fa085bb46cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "collator = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "66a91dd2-d059-4aa6-8ad6-b61b83a77364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d0e6715-125e-482f-a172-6cedb2b6982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(ds_split['train'], collate_fn=collator, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f0d5fb3-a59f-46c0-92f3-110148069b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c36967fa-59b1-43c8-986e-142f62317995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 3513,  1010,  1045,  ...,  3722, 10826,  2005],\n",
       "        [  103,  5150,  2046,  ...,  2052,  2022,  2986],\n",
       "        [ 1010,  1998,  1999,  ...,  1044, 18863,  2005],\n",
       "        ...,\n",
       "        [ 2031,  1037,  2309,  ...,  2056,  2009,  2001],\n",
       "        [ 2061,  2000,  3713,  ...,  2000,  5247,  2058],\n",
       "        [ 1045,  2001,  2012,  ..., 28248,  1998,  2980]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "        [3053, -100, -100,  ..., -100, -100, -100],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [2031, -100, -100,  ..., -100, -100, -100],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92446620-5611-4780-85fc-c995b650f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f710746a-5f19-4e85-bfc9-2ccd2649b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1578' max='29211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1578/29211 06:00 < 1:45:27, 4.37 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.437700</td>\n",
       "      <td>6.325556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 21\u001b[0m\n\u001b[1;32m      9\u001b[0m train_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     10\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout-bert\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39mtrain_args, train_dataset\u001b[38;5;241m=\u001b[39mds_split[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], eval_dataset\u001b[38;5;241m=\u001b[39mds_split[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], data_collator\u001b[38;5;241m=\u001b[39mcollator)\n\u001b[0;32m---> 21\u001b[0m yuri \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/dlp/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda/envs/dlp/lib/python3.12/site-packages/transformers/trainer.py:2284\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg.max_position_embeddings = 512\n",
    "cfg.num_hidden_layers = 6\n",
    "cfg.hidden_size = 384\n",
    "cfg.intermediate_size = 1536\n",
    "\n",
    "model = BertForMaskedLM(cfg)\n",
    "collator = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.2)\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir='out-bert',\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    num_train_epochs=1,\n",
    "    per_device_eval_batch_size=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    bf16=False, fp16=False, tf32=False, adam_beta1=0.9, adam_beta2=0.999,\n",
    "    learning_rate=2e-5, weight_decay=0.01, gradient_accumulation_steps=1, logging_strategy='steps', save_steps=500,\n",
    "    save_total_limit=10\n",
    ")\n",
    "trainer = Trainer(model=model, args=train_args, train_dataset=ds_split['train'], eval_dataset=ds_split['test'], data_collator=collator)\n",
    "yuri = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba449943-e3d4-46f0-b356-8585a3363eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2043, 1045,  ...,    0,    0,    0],\n",
       "        [ 101, 2326, 2001,  ...,    0,    0,    0],\n",
       "        [ 101, 2023, 1996,  ..., 1012, 1012, 1012],\n",
       "        [ 101, 2293, 2023,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100],\n",
       "        [-100, -100, -100,  ..., 1012, -100, -100],\n",
       "        [-100, -100, -100,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(ds_split['train'], collate_fn=collator, batch_size=4)\n",
    "for batch in loader:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4423ec6c-89c9-4bb2-a935-2c1a73e79524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 186368])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "765fc800-5864-48b1-8c7e-2ff6d8618bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fdb29050-20a4-4f2b-8bca-973e4a9fd4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc = ds_split['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc87c075-d259-4f9c-96d1-0d97beea4741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158208"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3862076f-d7b7-4383-b800-c01ba3a24b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6883e05a-5c9d-4fe0-9e6e-50b569a9d27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4669c46-a519-4d45-b36c-62c746b90d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
