{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de8c2ef-8aab-4dbe-bd90-0d5ae1a56a2a",
   "metadata": {},
   "source": [
    "* pip install datasets transformers evaluate jiwer\n",
    "* import torch, import datasets, import evaluate, import numpy as np, from dataclasses import data class, field. from typing import Any, Dict, List, Optional, Union\n",
    "* load train and test splits of mozilla-foundation/common voice 11 0” assamese dataset\n",
    "* for test, take only first 10 examples and proceed (otherwise you will hit Out of Memory Error)\n",
    "* from transformers import WhisperFeatureExtractor\n",
    "* Load feature extractor from the pretrained whisper tiny of openai\n",
    "* from transformers import WhisperTokenizer\n",
    "* load tokenizer of openai whisper tiny for assamese for asr task\n",
    "* from transformers import WhisperProcessor\n",
    "* load processor of openai whisper tiny for assamese for asr task\n",
    "* from datasets import Audio\n",
    "* convert audio to sampling rate of 16k\n",
    "* write a function which takes batches of input data and gives batches with features    extracted and corresponding labels from the tokenizer.\n",
    "* from transformers import WhisperForConditionalGeneration\n",
    "* model = WhisperForConditionalGeneration.from pretrained(”openai/whisper-tiny”)\n",
    "* set language to assamese, task to asr and forced decoder ids to none\n",
    "* Write a data collator\n",
    "* import evaluate and set metric = evaluate.load(”wer”)\n",
    "* write a function def compute metrics(pred) which takes predictions and returns wer\n",
    "* from transformers import Seq2SeqTrainingArguments\n",
    "* set the arguments for Seq2SeqTrainingArguments() as mentioned in the link `https://huggingface.co/blog/fine-tune-whisper` but change warmup steps to 50, max steps to 100, per device train batch size=8, per device eval batch size=1, save steps=100, eval steps=100\n",
    "* from transformers import Seq2SeqTrainer\n",
    "* Set the arguments based on the info mentioned in the above link\n",
    "* start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9698f1-ece1-45b3-a515-8253438104ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe36667-87f3-4540-a09a-84613596659d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9fc371341e497aa3a47b47b0f24599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/14.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2abf493c834586b304a79e6a1a6fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "common_voice_11_0.py:   0%|          | 0.00/8.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03822cfaf92f48428686b36c56cd3747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "languages.py:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e88736cbef242baaf25fe01e5d2fc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "release_stats.py:   0%|          | 0.00/60.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6525c79aff6141228ba471f3150b3d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "n_shards.json:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da707a1dc21e4977a89e6701891592da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "as_train_0.tar:   0%|          | 0.00/32.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc78654e2bd440cbcb9a92db4f04f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "as_dev_0.tar:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeac96a1a3f44b4ba24c20bf2cfffb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "as_test_0.tar:   0%|          | 0.00/12.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a2804bdeae4a3792faf698a4c8e5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "as_other_0.tar:   0%|          | 0.00/11.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69bdb381b624275852d7c7a3929b152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "as_invalidated_0.tar:   0%|          | 0.00/6.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e260869c8e0f473988986989667657c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.tsv:   0%|          | 0.00/236k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7768dfbb021d47eebec3e24964fa4cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.tsv:   0%|          | 0.00/144k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15915aa6fab432da1bae01a64f03690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv:   0%|          | 0.00/92.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4f6372877d470488456cb9b8b77208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "other.tsv:   0%|          | 0.00/82.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39e6f02b9214a4d9ba7f28ea666e9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "invalidated.tsv:   0%|          | 0.00/48.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d9be13b6a54b0e8c7fc38d74a182f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 824it [00:00, 229779.04it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ef236dec1f49b9b6e5f1c90dd2d8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 469it [00:00, 270470.04it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292f066bd0834752a835d5930c707ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 308it [00:00, 237253.56it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2276dca8b4874122bf0686b91c3abcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating other split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 297it [00:00, 268819.22it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2493a8c1104ab4a67808d487ff25b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating invalidated split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 163it [00:00, 257309.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# load train and test splits of mozilla-foundation/common-voice-11-0 Assamese\n",
    "ds_train = datasets.load_dataset('mozilla-foundation/common_voice_11_0', 'as', split='train')\n",
    "ds_test = datasets.load_dataset('mozilla-foundation/common_voice_11_0', 'as', split='train[:10]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a7a790-5269-468f-88c7-03bbe957cbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 824\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "826320c7-8bdd-434b-abd7-d7668e105cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4029a005-7373-4ac7-98f9-8c29d685a53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd2b53d5ee545ecadcc12ebc9c79911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import WhisperFeatureExtractor\n",
    "# Load feature extractor from the pretrained whisper tiny of openai\n",
    "\n",
    "from transformers import WhisperFeatureExtractor\n",
    "whisper_feat_extractor = WhisperFeatureExtractor.from_pretrained('openai/whisper-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45a162e-1bf5-4291-a3e9-c31e0e1c79a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b2eda2279d41a2869f91e7605733ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34ecfe93ef243e5b2eb5bad720650cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1147e57329cf49c4b6051b9c85cdff27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5be39fd68224895adbf529623e0ad87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959dd7f95034430fa1f812e40434ba4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f8b78c1bb14e31be4760f0b748d1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c5a697f63847299f7da74f838ee6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import WhisperTokenizer\n",
    "# load tokenizer of openai whisper tiny for assamese for asr task\n",
    "from transformers import WhisperTokenizer\n",
    "whisper_tokenizer = WhisperTokenizer.from_pretrained('openai/whisper-tiny', language='assamese', task='transcribe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184b563c-1518-44f6-b65f-3d6e980e20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processor of openai whisper tiny for assamese for asr task\n",
    "from transformers import WhisperProcessor\n",
    "whisper_processor = WhisperProcessor.from_pretrained('openai/whisper-tiny', language='assamese', task='transcribe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3c269-2e88-447b-91d9-e0900f6db58b",
   "metadata": {},
   "source": [
    "---\n",
    "1. How many examples are present in the train split of mozilla-foundation/common voice 11 0 ”assamese”\n",
    "langauge dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6e7b9a-4bfb-4baf-9433-441b4218791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 824\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2d1c9-f57c-4cb5-bb02-86fa8a64ab88",
   "metadata": {},
   "source": [
    "2. How many unique characters are there in the train split text ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "307dbe10-704a-44c0-89d6-2b111f5da755",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set()\n",
    "for sample in ds_train:\n",
    "    chars.update(sample['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5742c9f4-4832-44e7-be9e-636f33120371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d961c94b-2409-42fd-b560-1c5881513081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '?',\n",
       " '।',\n",
       " 'ঁ',\n",
       " 'ং',\n",
       " 'ঃ',\n",
       " 'অ',\n",
       " 'আ',\n",
       " 'ই',\n",
       " 'ঈ',\n",
       " 'উ',\n",
       " 'এ',\n",
       " 'ও',\n",
       " 'ঔ',\n",
       " 'ক',\n",
       " 'খ',\n",
       " 'গ',\n",
       " 'ঘ',\n",
       " 'ঙ',\n",
       " 'চ',\n",
       " 'ছ',\n",
       " 'জ',\n",
       " 'ঞ',\n",
       " 'ট',\n",
       " 'ঠ',\n",
       " 'ড',\n",
       " 'ঢ',\n",
       " 'ণ',\n",
       " 'ত',\n",
       " 'থ',\n",
       " 'দ',\n",
       " 'ধ',\n",
       " 'ন',\n",
       " 'প',\n",
       " 'ফ',\n",
       " 'ব',\n",
       " 'ভ',\n",
       " 'ম',\n",
       " 'য',\n",
       " 'র',\n",
       " 'ল',\n",
       " 'শ',\n",
       " 'ষ',\n",
       " 'স',\n",
       " 'হ',\n",
       " '়',\n",
       " 'া',\n",
       " 'ি',\n",
       " 'ী',\n",
       " 'ু',\n",
       " 'ূ',\n",
       " 'ৃ',\n",
       " 'ে',\n",
       " 'ৈ',\n",
       " 'ো',\n",
       " 'ৌ',\n",
       " '্',\n",
       " 'ৎ',\n",
       " 'ড়',\n",
       " 'ঢ়',\n",
       " 'য়',\n",
       " 'ৰ',\n",
       " 'ৱ',\n",
       " '৷',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b89be-eab1-4350-aa49-9d41f0918adc",
   "metadata": {},
   "source": [
    "3. What is the sampling rate of the original mozilla-foundation/common voice 11 0 ”assamese” language audio in Hz?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c64ca2d5-bd75-4c77-b0cd-1a4a4d27d7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3235137bf5b4ee2a9782e71d0c261ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{48000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = ds_train.map(lambda x: {'sampling_rate': x['audio']['sampling_rate']}, remove_columns=ds_train.column_names)\n",
    "set(sr['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3cac7a7-d840-42f6-9f12-85a846211257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f34c9fd7ded4d98b401ac2b75337ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{48000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try for test, too\n",
    "sr = ds_test.map(lambda x: {'sampling_rate': x['audio']['sampling_rate']}, remove_columns=ds_train.column_names)\n",
    "set(sr['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92158c95-278b-4d7b-9998-53ab0c71f061",
   "metadata": {},
   "source": [
    "4. What is the format of the mozilla-foundation/common voice 11 0 ”assamese” language audio ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b95430-6b35-44ac-a5f5-edf4cbd127c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1b29fbed5b40e2ae0d2062657cd89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'.mp3'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path as op\n",
    "\n",
    "audio_format = ds_train.map(lambda x: {'ext': op.splitext(x['audio']['path'])[-1]}, remove_columns=ds_train.column_names)\n",
    "set(audio_format['ext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19032ca8-e0ff-498b-80b8-b40928e23036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b4c2a16bb84a0994b5ceb6fdd49034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'.mp3'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try on test also\n",
    "audio_format = ds_test.map(lambda x: {'ext': op.splitext(x['audio']['path'])[-1]}, remove_columns=ds_train.column_names)\n",
    "set(audio_format['ext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef62ff7-fd40-463e-a296-03a082dd19bc",
   "metadata": {},
   "source": [
    "5. What will be the window length in msec if n fft is 400 in ”WhisperFeatureExtractor” ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcaece17-6245-4c9c-b844-1c0fdf493a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The window length in seconds is 400 / sampling_rate, in msec it is *= 1000\n",
    "400 / whisper_feat_extractor.sampling_rate * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ddbebc0-127c-44b0-ade8-e689d3fd19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [50258, 50350, 50359], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  What is the first token number after tokenising the 56th example?\n",
    "enc = whisper_tokenizer(ds_train[56]['sentence'])\n",
    "enc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b25f64-0548-49b3-9e9b-5ce027e03482",
   "metadata": {},
   "source": [
    "7. What is the token corresponding to the token number 51833 in whisper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3a0893d-d65b-44b3-9f79-162bd23616e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|29.38|>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token = {v: k for k, v in whisper_tokenizer.get_vocab().items()}\n",
    "id2token[51833]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46044e27-f536-43d3-9d83-4c4610808662",
   "metadata": {},
   "source": [
    "8. Is token number 51833 a special token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6137f28-a09d-4018-9f7f-8d79c8d76aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = whisper_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e526de3-4f4b-48bc-9982-5f5df334c094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51833"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['<|29.38|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26cfa177-9055-4133-939d-4d20bedba40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "51833 in whisper_tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce65fd1-19e9-4537-80aa-181bb0def8f9",
   "metadata": {},
   "source": [
    "9. What is the token corresponding to the token number 50350 in whisper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f67379f7-9bc2-47a8-a76b-057ff69c7aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|as|>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token[50350]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a3e05-b347-46e1-9e5c-3c2da917d45d",
   "metadata": {},
   "source": [
    "10. Is token number 50350 a special token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "493c6247-2842-4ba9-b3aa-63c86dd5959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50350 in whisper_tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "963bc644-98fa-41b6-821a-22a17ffeb3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_feat_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483d35a-8a6a-4307-9e34-7403b8987b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
